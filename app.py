import streamlit as st
import os
import time
import unicodedata
import re
import requests
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
import google.generativeai as genai

# ----------------------
# Configuration
# ----------------------
QDRANT_URL = "https://993e7bbb-cbe2-4b82-b672-90c4aed8585e.europe-west3-0.gcp.cloud.qdrant.io:6333"
QDRANT_API_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.qRNtWMTIR32MSM6KUe3lE5qJ0fS5KgyAf86EKQgQ1FQ"
COLLECTION_NAME = "arabic_documents_enhanced"

# API Keys
DEEPSEEK_API_KEY = "sk-14f267781a6f474a9d0ec8240383dae4"
DEEPSEEK_BASE_URL = "https://api.deepseek.com/v1"
GEMINI_API_KEY = "AIzaSyASlapu6AYYwOQAJJ3v-2FSKHnxIOZoPbY"

# Initialize Gemini
gemini_initial_configured = False
if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_initial_configured = True
        print("Gemini API configured successfully.")
    except Exception as e:
        print(f"Failed to configure Gemini API: {e}")

# ----------------------
# Enhanced Arabic Text Processing
# ----------------------
def normalize_arabic_text(text):
    """Enhanced Arabic text normalization for better search accuracy"""
    if not text:
        return text
    
    # Remove diacritics (ØªØ´ÙƒÙŠÙ„)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    
    # Normalize Arabic characters
    replacements = {
        'Ø£': 'Ø§', 'Ø¥': 'Ø§', 'Ø¢': 'Ø§', 'Ù±': 'Ø§',  # Alef variations
        'Ù‰': 'ÙŠ',  # Ya variations
        'Ø©': 'Ù‡',  # Ta marbuta
        'Ø¤': 'Ùˆ', 'Ø¦': 'ÙŠ',  # Hamza
        '\u200c': '',  # Zero-width non-joiner
        '\u200d': '',  # Zero-width joiner
        '\ufeff': '',  # BOM
        '\u200b': '',  # Zero-width space
        'ØŸ': '?', 'Ø›': ';', 'ØŒ': ',',  # Punctuation
    }
    
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    # Clean and normalize whitespace
    text = ' '.join(text.split())
    return text

def extract_arabic_keywords(text):
    """Extract meaningful Arabic keywords by removing stop words"""
    if not text:
        return []
    
    # Comprehensive Arabic stop words
    arabic_stopwords = {
        # Pronouns
        'Ù‡Ùˆ', 'Ù‡ÙŠ', 'Ù‡Ù…', 'Ù‡Ù†', 'Ø£Ù†Øª', 'Ø£Ù†ØªÙ…', 'Ø£Ù†ØªÙ†', 'Ø£Ù†Ø§', 'Ù†Ø­Ù†',
        'Ø¥ÙŠØ§Ù‡', 'Ø¥ÙŠØ§Ù‡Ø§', 'Ø¥ÙŠØ§Ù‡Ù…', 'Ø¥ÙŠØ§Ù‡Ù†', 'Ø¥ÙŠØ§Ùƒ', 'Ø¥ÙŠØ§ÙƒÙ…', 'Ø¥ÙŠØ§ÙƒÙ†', 'Ø¥ÙŠØ§ÙŠ', 'Ø¥ÙŠØ§Ù†Ø§',
        
        # Demonstratives
        'Ù‡Ø°Ø§', 'Ù‡Ø°Ù‡', 'Ø°Ù„Ùƒ', 'ØªÙ„Ùƒ', 'Ø£ÙˆÙ„Ø¦Ùƒ', 'Ù‡Ø¤Ù„Ø§Ø¡', 'Ø§Ù„ØªÙŠ', 'Ø§Ù„Ø°ÙŠ', 'Ø§Ù„Ù„Ø°Ø§Ù†', 'Ø§Ù„Ù„ØªØ§Ù†',
        
        # Prepositions
        'ÙÙŠ', 'Ù…Ù†', 'Ø¥Ù„Ù‰', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ù…Ø¹', 'Ø¨Ø¹Ø¯', 'Ù‚Ø¨Ù„', 'ØªØ­Øª', 'ÙÙˆÙ‚', 'Ø£Ù…Ø§Ù…', 'Ø®Ù„Ù',
        'Ø¨ÙŠÙ†', 'Ø¶Ø¯', 'Ù†Ø­Ùˆ', 'Ø­ÙˆÙ„', 'Ø¯ÙˆÙ†', 'Ø³ÙˆÙ‰', 'Ø®Ù„Ø§Ù„', 'Ø¹Ø¨Ø±', 'Ù„Ø¯Ù‰', 'Ø¹Ù†Ø¯',
        
        # Conjunctions and particles
        'Ùˆ', 'Ø£Ùˆ', 'Ø£Ù…', 'Ù„ÙƒÙ†', 'Ù„ÙƒÙ†', 'ØºÙŠØ±', 'Ø¥Ù„Ø§', 'Ø¨Ù„', 'Ø«Ù…', 'ÙƒØ°Ù„Ùƒ',
        'Ø£Ù†', 'Ø¥Ù†', 'ÙƒÙŠ', 'Ù„ÙƒÙŠ', 'Ø­ØªÙ‰', 'Ù„ÙˆÙ„Ø§', 'Ù„ÙˆÙ…Ø§', 'Ù„Ùˆ', 'Ø¥Ø°Ø§', 'Ø¥Ø°', 'Ø­ÙŠØ«',
        
        # Auxiliaries and modals
        'ÙƒØ§Ù†', 'ÙƒØ§Ù†Øª', 'ÙƒØ§Ù†ÙˆØ§', 'ÙƒÙ†', 'ÙŠÙƒÙˆÙ†', 'ØªÙƒÙˆÙ†', 'ÙŠÙƒÙˆÙ†ÙˆØ§', 'ØªÙƒÙ†',
        'Ù‚Ø¯', 'Ù„Ù‚Ø¯', 'Ø³ÙˆÙ', 'Ù„Ù†', 'Ù„Ù…', 'Ù„Ù…Ø§', 'Ù„ÙŠØ³', 'Ù„ÙŠØ³Øª', 'Ù„ÙŠØ³ÙˆØ§', 'Ù„Ø³Ù†',
        
        # Question words
        'Ù…Ø§', 'Ù…Ø§Ø°Ø§', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù„Ù…Ø§Ø°Ø§', 'ÙƒÙ…', 'Ø£ÙŠ', 'Ø£ÙŠØ©', 'ÙƒÙŠÙ', 'Ø£Ù†Ù‰',
        
        # Articles and determiners
        'Ø§Ù„', 'ÙƒÙ„', 'Ø¬Ù…ÙŠØ¹', 'Ø¨Ø¹Ø¶', 'Ù…Ø¹Ø¸Ù…',
        
        # Common short words
        'Ù', 'Ø¨', 'Ùƒ', 'Ù„', 'Ø¹Ù†', 'Ù„Ø§', 'Ù†Ø¹Ù…', 'ÙƒÙ„Ø§'
    }
    
    # Extract Arabic words (2+ characters)
    words = re.findall(r'[\u0600-\u06FF\u0750-\u077F]{2,}', text)
    
    # Filter out stop words and normalize
    keywords = []
    for word in words:
        normalized_word = normalize_arabic_text(word)
        if len(normalized_word) > 2 and normalized_word not in arabic_stopwords:
            keywords.append(normalized_word)
    
    return list(set(keywords))  # Remove duplicates

# ----------------------
# CSS Styling
# ----------------------
def load_arabic_css():
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Arabic:wght@300;400;500;600;700&display=swap');
    body { font-family: 'Noto Sans Arabic', sans-serif; direction: rtl; }
    .main-header { text-align: center; color: #2E8B57; font-family: 'Noto Sans Arabic', sans-serif; font-size: 2.5rem; font-weight: 700; margin-bottom: 0.5rem; direction: rtl; }
    .sub-header { text-align: center; color: #666; font-family: 'Noto Sans Arabic', sans-serif; font-size: 1.2rem; font-weight: 400; margin-bottom: 1rem; direction: rtl; }
    .stExpander .stExpanderHeader { font-size: 1.1rem !important; font-weight: 600 !important; font-family: 'Noto Sans Arabic', sans-serif; direction: rtl; } 
    .stExpander div[data-testid="stExpanderDetails"] { direction: rtl; } 
    .stTextArea > div > div > textarea { direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; font-size: 1.1rem; min-height: 100px !important; border-radius: 10px; border: 1px solid #ccc; }
    .search-button-container { text-align: center; margin-top: 1rem; margin-bottom: 1rem; }
    div[data-testid="stButton"] > button { margin: 0 auto; display: block; font-family: 'Noto Sans Arabic', sans-serif; font-size: 1.1rem; font-weight: 600; border-radius: 8px; transition: background-color 0.2s ease, transform 0.2s ease; }
    div[data-testid="stButton"] > button:hover { transform: translateY(-2px); }
    .chat-container { direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; }
    .user-message { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 1rem; border-radius: 15px 15px 5px 15px; margin: 0.5rem 0; direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; font-size: 1.1rem; font-weight: 500; box-shadow: 0 2px 10px rgba(0,0,0,0.1); word-wrap: break-word; }
    .bot-message { background: linear-gradient(135deg, #5DADE2 0%, #3498DB 100%); color: white; padding: 1rem; border-radius: 15px 15px 15px 5px; margin: 0.5rem 0; direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; font-size: 1.1rem; font-weight: 500; line-height: 1.8; box-shadow: 0 2px 10px rgba(0,0,0,0.1); word-wrap: break-word; }
    .time-taken { font-size: 0.8rem; color: #777; margin-top: 0.3rem; direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif;}
    .debug-info { background: #fff3cd; padding: 0.5rem; border-radius: 5px; margin: 0.5rem 0; font-size: 0.85rem; direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; border: 1px solid #ffeeba; word-wrap: break-word; }
    .debug-info-results { font-size: 0.8rem; white-space: pre-wrap; word-break: break-all; }
    .api-used { background: #e3f2fd; color: #1976d2; padding: 0.3rem 0.6rem; border-radius: 5px; font-size: 0.85rem; margin-top: 0.5rem; display: inline-block; font-family: 'Noto Sans Arabic', sans-serif; }
    .source-container { display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 8px; margin-top: 1rem; direction: rtl; } 
    .source-info { background: #f0f2f6; padding: 0.25rem 0.4rem; border-radius: 6px; font-size: 0.75rem; color: #555; direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; border: 1px solid #ddd; transition: transform 0.2s ease-in-out; display: flex; flex-direction: column; justify-content: center; overflow-wrap: break-word; word-break: break-word; min-height: 50px; }
    .source-info strong { font-size: 0.8rem; } 
    .source-info:hover { transform: translateY(-2px); box-shadow: 0 2px 4px rgba(0,0,0,0.08); }
    .status-active { color: #28a745; font-weight: bold; }
    .status-inactive { color: #dc3545; font-weight: bold; }
    .radio-label-status-active { color: #28a745 !important; font-weight: normal !important; font-size:0.9em !important; }
    .radio-label-status-inactive { color: #dc3545 !important; font-weight: normal !important; font-size:0.9em !important; }
    .search-accuracy-boost { background: #d4edda; border: 1px solid #c3e6cb; padding: 0.5rem; border-radius: 5px; margin: 0.5rem 0; font-family: 'Noto Sans Arabic', sans-serif; direction: rtl; text-align: right; }
    </style>
    """, unsafe_allow_html=True)

# ----------------------
# Initialize Components
# ----------------------
@st.cache_resource
def init_qdrant_client():
    try:
        return QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY, timeout=10)
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Qdrant: {e}")
        return None

@st.cache_resource
def init_embedding_model():
    try:
        return SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†: {e}")
        return None

# ----------------------
# IMPROVED SEARCH FUNCTION - Fixed for Better Accuracy
# ----------------------
def comprehensive_search(query, max_results=50):
    """
    Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ Ø¯Ù‚Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    Ù…ØµÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØºÙŠØ± Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
    """
    
    embedding_model = init_embedding_model()
    if not embedding_model:
        return [], "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†.", []
    
    qdrant_client = init_qdrant_client()
    if not qdrant_client:
        return [], "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Qdrant.", []
    
    try:
        print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: '{query}'")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ø¹ØªØ¨Ø§Øª Ø£Ù‚Ù„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
        search_variants = []
        
        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø£ØµÙ„ÙŠ - Ø¹ØªØ¨Ø© Ù…Ù†Ø®ÙØ¶Ø©
        search_variants.append(('original', query, 0.1))
        
        # 2. Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ø¨Ø¹
        normalized_query = normalize_arabic_text(query)
        if normalized_query != query and normalized_query:
            search_variants.append(('normalized', normalized_query, 0.08))
        
        # 3. Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = extract_arabic_keywords(query)
        if keywords:
            keywords_text = ' '.join(keywords)
            search_variants.append(('keywords', keywords_text, 0.05))
            
            # 4. Ø§Ù„Ø¨Ø­Ø« Ø¨ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ÙØ±Ø¯ÙŠØ© Ù…Ù‡Ù…Ø©
            important_keywords = [kw for kw in keywords if len(kw) > 3][:3]
            for keyword in important_keywords:
                search_variants.append(('single_keyword', keyword, 0.03))
        
        # 5. Ø§Ù„Ø¨Ø­Ø« Ø¨ÙƒÙ„Ù…Ø§Øª ÙØ±Ø¯ÙŠØ© Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø£ØµÙ„ÙŠ
        individual_words = [w.strip() for w in query.split() if len(w.strip()) > 3][:2]
        for word in individual_words:
            search_variants.append(('individual_word', word, 0.02))
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ ÙƒÙ„ Ù…ØªØºÙŠØ±
        all_results = []
        seen_ids = set()
        search_details = []
        
        print(f"ğŸ“Š Ø³ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø± {len(search_variants)} Ù…ØªØºÙŠØ± Ø¨Ø­Ø«...")
        
        for variant_type, variant_query, threshold in search_variants:
            try:
                # Ø¥Ù†Ø´Ø§Ø¡ embedding Ù„Ù„Ù…ØªØºÙŠØ±
                query_embedding = embedding_model.encode([variant_query])[0].tolist()
                
                # Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØºÙŠØ±
                variant_results = qdrant_client.search(
                    collection_name=COLLECTION_NAME,
                    query_vector=query_embedding,
                    limit=max_results,
                    with_payload=True,
                    score_threshold=threshold
                )
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±)
                new_results_count = 0
                for result in variant_results:
                    if result.id not in seen_ids and result.payload:
                        # ÙØ­Øµ Ø£Ù† Ø§Ù„Ù†Øµ Ù„ÙŠØ³ ÙØ§Ø±ØºØ§Ù‹ ÙˆØ°Ùˆ Ù…Ø¹Ù†Ù‰
                        text = result.payload.get('text', '')
                        if len(text.strip()) > 20:  # Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 20 Ø­Ø±Ù
                            seen_ids.add(result.id)
                            all_results.append(result)
                            new_results_count += 1
                
                search_details.append(f"{variant_type} (Ø¹ØªØ¨Ø© {threshold}): {new_results_count} Ù†ØªÙŠØ¬Ø©")
                print(f"âœ… {variant_type}: {new_results_count} Ù†ØªÙŠØ¬Ø© Ø¬Ø¯ÙŠØ¯Ø©")
                
                # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ù†ØªØ§Ø¦Ø¬ ÙƒØ§ÙÙŠØ© Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰ØŒ Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ù„Ù„Ø¨Ø§Ù‚ÙŠ
                if len(all_results) >= 15 and variant_type in ['original', 'normalized']:
                    print(f"ğŸ¯ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(all_results)} Ù†ØªÙŠØ¬Ø© ÙƒØ§ÙÙŠØ©ØŒ ØªÙˆÙ‚Ù Ø§Ù„Ø¨Ø­Ø«")
                    break
                    
            except Exception as e:
                search_details.append(f"{variant_type}: Ø®Ø·Ø£ ({str(e)[:30]})")
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ {variant_type}: {e}")
                continue
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· (Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø£ÙˆÙ„Ø§Ù‹)
        all_results.sort(key=lambda x: x.score, reverse=True)
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        final_results = all_results[:max_results]
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„ØªØ´Ø®ÙŠØµ
        initial_search_details = []
        if final_results:
            initial_search_details = [
                {
                    "id": r.id,
                    "score": r.score,
                    "source": r.payload.get('source', 'N/A') if r.payload else 'N/A',
                    "text_preview": (r.payload.get('text', '')[:150] + "...") if r.payload else ''
                }
                for r in final_results[:12]  # Ø£ÙØ¶Ù„ 12 Ù†ØªÙŠØ¬Ø© Ù„Ù„ØªØ´Ø®ÙŠØµ
            ]
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø­Ø«
        successful_variants = len([d for d in search_details if 'Ø®Ø·Ø£' not in d and ': 0 Ù†ØªÙŠØ¬Ø©' not in d])
        search_info = f"Ø¨Ø­Ø« Ù…Ø­Ø³Ù† Ù„Ù„Ø¯Ù‚Ø©: {len(final_results)} Ù†ØªÙŠØ¬Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ù† {successful_variants}/{len(search_variants)} Ù…ØªØºÙŠØ±. " + " | ".join(search_details[:5])  # Ø£ÙˆÙ„ 5 ØªÙØ§ØµÙŠÙ„
        
        print(f"âœ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {len(final_results)}")
        if final_results:
            best_result = final_results[0]
            print(f"ğŸ¯ Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©: {best_result.payload.get('source', 'Unknown')} (Ù†Ù‚Ø§Ø·: {best_result.score:.3f})")
            print(f"ğŸ“„ Ù…Ø¹Ø§ÙŠÙ†Ø©: {best_result.payload.get('text', '')[:100]}...")
        
        return final_results, search_info, initial_search_details
        
    except Exception as e:
        error_msg = f"Ø®Ø·Ø£ Ø´Ø§Ù…Ù„ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù†: {str(e)}"
        print(f"âŒ {error_msg}")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®ÙŠØ±Ø© Ø¨Ø­Ø« Ø¨Ø³ÙŠØ· Ø¨Ø¹ØªØ¨Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹
        try:
            print("ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø­Ø« Ø·ÙˆØ§Ø±Ø¦...")
            emergency_embedding = embedding_model.encode([query])[0].tolist()
            emergency_results = qdrant_client.search(
                collection_name=COLLECTION_NAME,
                query_vector=emergency_embedding,
                limit=max_results,
                with_payload=True,
                score_threshold=0.01  # Ø¹ØªØ¨Ø© Ø·ÙˆØ§Ø±Ø¦ Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹
            )
            
            emergency_details = [
                {
                    "id": r.id,
                    "score": r.score,
                    "source": r.payload.get('source', 'N/A') if r.payload else 'N/A',
                    "text_preview": (r.payload.get('text', '')[:100] + "...") if r.payload else ''
                }
                for r in emergency_results[:10]
            ]
            
            return emergency_results, f"{error_msg} | Ø¨Ø­Ø« Ø·ÙˆØ§Ø±Ø¦: {len(emergency_results)} Ù†ØªÙŠØ¬Ø©", emergency_details
            
        except Exception as emergency_error:
            return [], f"{error_msg} | ÙØ´Ù„ Ø¨Ø­Ø« Ø§Ù„Ø·ÙˆØ§Ø±Ø¦: {str(emergency_error)}", []

# ----------------------
# API Response Functions
# ----------------------
def prepare_llm_messages(user_question, context, context_info):
    system_prompt = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒØªØ¨ ÙˆØ§Ø³ØªÙØªØ§Ø¡Ø§Øª Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯ ÙÙ‚Ø·.\nÙ‚ÙˆØ§Ø¹Ø¯ Ø­ØªÙ…ÙŠØ© Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¬Ø§ÙˆØ²Ù‡Ø§:\n1. Ø£Ø¬Ø¨ ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¹Ø·Ø§Ø© Ø£Ø¯Ù†Ø§Ù‡ (\"Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©\") - Ù„Ø§ Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª.\n2. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµØŒ Ù‚Ù„ Ø¨ÙˆØ¶ÙˆØ­: \"Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§ÙÙŠØ© ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¨Ø®ØµÙˆØµ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.\"\n3. Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¹Ø·Ø§Ø©. Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ Ø§Ù„Ø¹Ø§Ù…Ø© Ø£Ùˆ Ù…Ø¹Ø±ÙØªÙƒ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.\n4. Ø§Ù‚ØªØ¨Ø³ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ØŒ Ù…Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹ ÙÙŠ Ø§Ù„Ù†Øµ (Ù…Ø«Ø§Ù„: [Ù†Øµ Ù¡]).\n5. Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ø¥Ø¬Ø§Ø¨Ø© Ø¬Ø²Ø¦ÙŠØ©ØŒ Ø§Ø°ÙƒØ±Ù‡Ø§ ÙˆØ£ÙˆØ¶Ø­ Ø£Ù†Ù‡Ø§ ØºÙŠØ± ÙƒØ§Ù…Ù„Ø© Ø£Ùˆ ØªØºØ·ÙŠ Ø¬Ø§Ù†Ø¨Ø§Ù‹ Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„.\n6. Ù‡Ø¯ÙÙƒ Ù‡Ùˆ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙˆØ«ÙˆÙ‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø§ Ù‡Ùˆ Ù…ØªÙˆÙØ± ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·.\n7. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØµÙˆØµ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ù„Ø§ ØªØ­Ø§ÙˆÙ„ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø£Ùˆ ØªØ®Ù…ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©.\nØªØ°ÙƒØ±: Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù„ÙŠØ³Øª ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø£Ø¯Ù†Ø§Ù‡ = Ù„Ø§ ØªØ°ÙƒØ±Ù‡Ø§ Ø£Ø¨Ø¯Ø§Ù‹. ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ ÙˆÙ…Ù‚ØªØµØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø±."
    user_content = f"Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø·Ø±ÙˆØ­: {user_question}\n\nØ§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ‚Ø· (Ø£Ø¬Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡Ø§ Ø­ØµØ±Ø§Ù‹):\n{context}\n\nÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù† Ø§Ù„Ø³ÙŠØ§Ù‚: {context_info}\n\nØ§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª: ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø£Ø¹Ù„Ø§Ù‡ ÙÙ‚Ø·. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ ÙˆØ¶Ø­ Ø°Ù„Ùƒ."
    return [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]

def get_deepseek_response(messages, max_tokens=2000):
    if not DEEPSEEK_API_KEY:
        return "DeepSeek API key Ù…ÙÙ‚ÙˆØ¯."
    try:
        headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
        data = {"model": "deepseek-chat", "messages": messages, "temperature": 0.05, "max_tokens": max_tokens, "stream": False}
        response = requests.post(f"{DEEPSEEK_BASE_URL}/chat/completions", headers=headers, json=data, timeout=90)
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content'] if result.get('choices') and result['choices'][0].get('message') else "Ù„Ù… ÙŠØªÙ…ÙƒÙ† DeepSeek Ù…Ù† Ø§Ù„Ø±Ø¯."
    except requests.exceptions.Timeout:
        return "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© DeepSeek."
    except requests.exceptions.HTTPError as e:
        err_content = e.response.text if e.response else "No response"
        return f"Ø®Ø·Ø£ DeepSeek: {e.response.status_code if e.response else 'N/A'}. ØªÙØ§ØµÙŠÙ„: {err_content[:200]}"
    except Exception as e:
        return f"Ø®Ø·Ø£ DeepSeek: {str(e)}"

def get_gemini_response(messages, max_tokens=2000):
    global gemini_initial_configured
    if not GEMINI_API_KEY:
        return "Gemini API key Ù…ÙÙ‚ÙˆØ¯."
    try:
        if not gemini_initial_configured:
            genai.configure(api_key=GEMINI_API_KEY)
            gemini_initial_configured = True
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        proc_msgs, sys_prompt_txt = [], None
        
        if messages and messages[0]["role"] == "system":
            sys_prompt_txt = messages[0]["content"]
            for msg in messages[1:]:
                proc_msgs.append({"role": "user" if msg["role"]=="user" else "model", "parts": [msg["content"]]})
        else:
            for msg in messages:
                proc_msgs.append({"role": "user" if msg["role"]=="user" else "model", "parts": [msg["content"]]})
        
        if sys_prompt_txt:
            if proc_msgs and proc_msgs[0]["role"] == "user":
                proc_msgs[0]["parts"][0] = f"{sys_prompt_txt}\n\n---\n\n{proc_msgs[0]['parts'][0]}"
            else:
                proc_msgs.insert(0, {"role": "user", "parts": [sys_prompt_txt]})
        
        if not proc_msgs:
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ø³Ø§Ø¦Ù„ ØµØ§Ù„Ø­Ø© Ù„Ù€ Gemini."
        
        if len(proc_msgs) > 1 and proc_msgs[-1]["role"] == "user":
            hist, curr_msg = proc_msgs[:-1], proc_msgs[-1]["parts"][0]
            chat = model.start_chat(history=hist)
            resp = chat.send_message(curr_msg, generation_config=genai.types.GenerationConfig(temperature=0.05, max_output_tokens=max_tokens))
        elif proc_msgs and proc_msgs[0]["role"] == "user":
            resp = model.generate_content(proc_msgs[0]["parts"], generation_config=genai.types.GenerationConfig(temperature=0.05, max_output_tokens=max_tokens))
        else:
            return "Ø¨Ù†ÙŠØ© Ø±Ø³Ø§Ø¦Ù„ Gemini ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©."
        
        return resp.text
    except Exception as e:
        return f"Ø®Ø·Ø£ Gemini: {str(e)}"

# ----------------------
# Status Functions
# ----------------------
@st.cache_data(ttl=300)
def get_qdrant_info():
    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY, timeout=5)
        collection_info = client.get_collection(COLLECTION_NAME)
        return {
            "status": True,
            "message": f"Ù…ØªØµÙ„ âœ“ | Ø§Ù„Ù†Ù‚Ø§Ø·: {collection_info.points_count:,}",
            "details": {
                "Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©": COLLECTION_NAME,
                "Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø·": collection_info.points_count,
                "Ø­Ø§Ù„Ø© Ø§Ù„ÙÙ‡Ø±Ø³Ø©": str(collection_info.status),
                "ØªÙ‡ÙŠØ¦Ø© Vector": str(collection_info.config.params)
            }
        }
    except Exception as e:
        if "Not found: Collection" in str(e) or "NOT_FOUND" in str(e).upper():
            return {"status": False, "message": f"ØºÙŠØ± Ù…ØªØµÙ„ (Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© '{COLLECTION_NAME}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©)", "details": {}}
        return {"status": False, "message": f"ØºÙŠØ± Ù…ØªØµÙ„ (Ø®Ø·Ø£: {type(e).__name__})", "details": {}}

@st.cache_data(ttl=300)
def check_api_status(api_name):
    global gemini_initial_configured
    if api_name == "DeepSeek":
        if not DEEPSEEK_API_KEY:
            return False, "Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯"
        try:
            headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
            data = {"model": "deepseek-chat", "messages": [{"role": "user", "content": "Ù…Ø±Ø­Ø¨Ø§"}], "max_tokens": 1, "stream": False}
            response = requests.post(f"{DEEPSEEK_BASE_URL}/chat/completions", headers=headers, json=data, timeout=7)
            return (True, "Ù†Ø´Ø· âœ“") if response.status_code == 200 else (False, f"Ø®Ø·Ø£ ({response.status_code})")
        except Exception as e:
            return False, f"ØºÙŠØ± Ù†Ø´Ø· ({type(e).__name__})"
    elif api_name == "Gemini":
        if not GEMINI_API_KEY:
            return False, "Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯"
        try:
            if not gemini_initial_configured:
                genai.configure(api_key=GEMINI_API_KEY)
                gemini_initial_configured = True
            model = genai.GenerativeModel('gemini-1.5-flash')
            model.generate_content("test", generation_config=genai.types.GenerationConfig(candidate_count=1, max_output_tokens=1))
            return True, "Ù†Ø´Ø· âœ“"
        except Exception as e:
            err = str(e).lower()
            if "api_key_invalid" in err or "permission" in err or "quota" in err or "authentication" in err:
                return False, "Ø®Ø·Ø£ Ø¨Ø§Ù„Ù…ÙØªØ§Ø­"
            return False, f"ØºÙŠØ± Ù†Ø´Ø· ({type(e).__name__})"
    return False, "API ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

# ----------------------
# Main Application
# ----------------------
def main():
    st.set_page_config(page_title="Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø³Ù†Ø¯ - Ø¨Ø­Ø«", page_icon="ğŸ•Œ", layout="wide", initial_sidebar_state="collapsed")
    load_arabic_css()
    
    st.markdown('<h1 class="main-header">Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¯ÙŠÙ†ÙŠ Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Ù…Ø­Ø±Ùƒ Ø¨Ø­Ø« Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ø§Ø³ØªÙØªØ§Ø¡Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù† - Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©</p>', unsafe_allow_html=True)

    # Settings Section
    with st.expander("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ­Ø§Ù„Ø© Ø§Ù„Ø£Ù†Ø¸Ù…Ø©", expanded=True):
        st.markdown("<div style='text-align: right; font-weight: bold; margin-bottom: 0.5rem;'>Ø§Ø®ØªØ± Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:</div>", unsafe_allow_html=True)
        
        # Check API status
        deepseek_ok, deepseek_msg = check_api_status("DeepSeek")
        gemini_ok, gemini_msg = check_api_status("Gemini")
        
        llm_options = ["DeepSeek", "Gemini"]
        llm_captions = [
            f"<span class='{'radio-label-status-active' if deepseek_ok else 'radio-label-status-inactive'}'>({deepseek_msg})</span>",
            f"<span class='{'radio-label-status-active' if gemini_ok else 'radio-label-status-inactive'}'>({gemini_msg})</span>"
        ]
        
        default_index = 0 if deepseek_ok else (1 if gemini_ok else 0)
        if not deepseek_ok and not gemini_ok:
            st.warning("ØªÙ†Ø¨ÙŠÙ‡: Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù†Ø´Ø·Ø©.", icon="âš ï¸")
        
        selected_llm = st.radio("Ù…Ø­Ø±ÙƒØ§Øª AI:", llm_options, captions=llm_captions, index=default_index, horizontal=True, key="llm_sel", label_visibility="collapsed")
        
        st.markdown("---")
        st.markdown("<div style='text-align: right; font-weight: bold; margin-bottom: 0.5rem;'>##### Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Qdrant):</div>", unsafe_allow_html=True)
        qdrant_info = get_qdrant_info()
        status_class = "status-active" if qdrant_info["status"] else "status-inactive"
        st.markdown(f'<div style="display: flex; justify-content: center;"><div style="background: #f0f2f6; padding: 0.5rem; border-radius: 8px; text-align: center; font-family: \'Noto Sans Arabic\', sans-serif; direction: rtl; border: 1px solid #e0e0e0; font-size: 0.9rem; margin-bottom: 0.5rem; width: 90%; max-width: 450px;">Qdrant DB: <span class="{status_class}">{qdrant_info["message"]}</span></div></div>', unsafe_allow_html=True)

        st.markdown("<div style='text-align: right; font-weight: bold; margin-top:0.5rem;'>Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¨Ø­Ø«:</div>", unsafe_allow_html=True)
        search_levels = ["Ø¨Ø­Ø« Ø³Ø±ÙŠØ¹ (15)", "Ø¨Ø­Ø« Ù…ØªÙˆØ³Ø· (30)", "Ø¨Ø­Ø« Ø´Ø§Ù…Ù„ (50)"]
        selected_level = st.radio("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¨Ø­Ø«:", search_levels, index=1, horizontal=True, key="s_depth_radio", label_visibility="collapsed")
        max_results = {"Ø¨Ø­Ø« Ø³Ø±ÙŠØ¹ (15)": 15, "Ø¨Ø­Ø« Ù…ØªÙˆØ³Ø· (30)": 30, "Ø¨Ø­Ø« Ø´Ø§Ù…Ù„ (50)": 50}[selected_level]
        
        show_debug = st.checkbox("Ø¥Ø¸Ù‡Ø§Ø± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙØµÙŠÙ„ÙŠØ©", value=True, key="debug_cb")

    # Database info section
    if qdrant_info['status'] and qdrant_info.get('details'):
        with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", expanded=False):
            details = qdrant_info['details']
            info_html = f"<div style='direction: rtl; padding: 1rem; background-color: #e9ecef; border-radius: 10px; margin-top:1rem; margin-bottom: 1.5rem; border: 1px solid #ced4da;'>"
            info_html += f"<h3 style='font-family: \"Noto Sans Arabic\", sans-serif; text-align:right; color: #495057;'>Ù…Ø¬Ù…ÙˆØ¹Ø©: {details.get('Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©', COLLECTION_NAME)}</h3>"
            for k, v in details.items():
                if k != "Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©":
                    info_html += f"<p style='font-family: \"Noto Sans Arabic\", sans-serif; text-align:right; margin-bottom: 0.3rem;'><strong>{k}:</strong> {v}</p>"
            info_html += "</div>"
            st.markdown(info_html, unsafe_allow_html=True)
    elif not qdrant_info['status']:
        st.warning(f"Qdrant: {qdrant_info['message']}.", icon="âš ï¸")

    # Chat history initialization
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display chat history
    chat_container = st.container()
    with chat_container:
        st.markdown('<div class="chat-container">', unsafe_allow_html=True)
        for msg_item in st.session_state.messages:
            is_user = msg_item["role"] == "user"
            icon = "ğŸ‘¤" if is_user else "ğŸ¤–"
            css_class = "user-message" if is_user else "bot-message"
            st.markdown(f'<div class="{css_class}">{icon} {msg_item["content"]}</div>', unsafe_allow_html=True)
            
            if not is_user:
                # Show API used
                if "api_used" in msg_item:
                    st.markdown(f'<span class="api-used">Ø§Ø³ØªØ®Ø¯Ù…: {msg_item["api_used"]}</span>', unsafe_allow_html=True)
                
                # Show time taken
                if "time_taken" in msg_item:
                    st.markdown(f'<div class="time-taken">â±ï¸ Ø²Ù…Ù†: {msg_item["time_taken"]:.2f} Ø«</div>', unsafe_allow_html=True)
                
                # Show debug info if enabled
                if show_debug:
                    debug_parts = []
                    if "debug_info" in msg_item:
                        debug_parts.append(msg_item["debug_info"])
                    
                    if "initial_search_details" in msg_item and msg_item["initial_search_details"]:
                        details_str_parts = []
                        for d_idx, d in enumerate(msg_item["initial_search_details"]):
                            display_id = str(d.get('id', 'N/A'))
                            details_str_parts.append(f"  {d_idx+1}. ID: {display_id[:8]}... | Score: {d.get('score', 0):.3f} | Source: {d.get('source', 'N/A')} | Preview: {d.get('text_preview', 'N/A')}")
                        details_str = "\n".join(details_str_parts)
                        debug_parts.append(f"Ù†ØªØ§Ø¦Ø¬ Qdrant Ø§Ù„Ù…ÙØµÙ„Ø© ({len(msg_item['initial_search_details'])}):\n{details_str}")
                    
                    if debug_parts:
                        st.markdown(f'<div class="debug-info">ğŸ” Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙØµÙŠÙ„ÙŠØ©:<div class="debug-info-results">{"<hr>".join(debug_parts)}</div></div>', unsafe_allow_html=True)

                # Show sources
                if "sources" in msg_item and msg_item["sources"]:
                    st.markdown("<div style='text-align: right; margin-top:0.5rem;'><strong>Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:</strong></div><div class='source-container'>", unsafe_allow_html=True)
                    for j_idx in range(0, min(len(msg_item["sources"]), 9), 3):
                        cols = st.columns(3)
                        for k_idx, k_src_item in enumerate(msg_item["sources"][j_idx:j_idx+3]):
                            with cols[k_idx]:
                                source = k_src_item.get("source", "N/A")
                                score = k_src_item.get("score", 0)
                                st.markdown(f'<div class="source-info" title="S: {source}\nSc: {score*100:.1f}%">ğŸ“„ <strong>{source}</strong><br>ØªØ·Ø§Ø¨Ù‚: {score*100:.1f}%</div>', unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # Search input section
    st.markdown("<hr style='margin-top:1.5rem; margin-bottom:0.5rem;'>", unsafe_allow_html=True)
    
    # Accuracy improvement notice
    st.markdown('<div class="search-accuracy-boost">ğŸ¯ <strong>ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¯Ù‚Ø© Ø§Ù„Ø¨Ø­Ø«:</strong> ØªÙ… ØªØ­Ø³ÙŠÙ† Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ø¨Ø­Ø« Ù„ØªÙ‚Ø¯ÙŠÙ… Ù†ØªØ§Ø¦Ø¬ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© ÙˆØµÙ„Ø© Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ</div>', unsafe_allow_html=True)
    
    _, input_main, _ = st.columns([0.2, 2.6, 0.2])
    with input_main:
        user_query = st.text_area("Ø³Ø¤Ø§Ù„Ùƒ...", placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ (Ù…Ø«Ø§Ù„: ØµÙ„Ø§Ø© Ù„ÙŠÙ„Ø© Ø§Ù„Ø±ØºØ§Ø¦Ø¨ØŒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ³Ø§Ù…Ø­ ÙÙŠ Ø£Ø¯Ù„Ø© Ø§Ù„Ø³Ù†Ù†ØŒ Ø­ÙƒÙ… Ø§Ù„Ø³ÙŠÙ„ÙÙŠ ÙÙŠ Ø§Ù„Ø¥Ø­Ø±Ø§Ù…)...", key="user_input", height=120, label_visibility="collapsed")
        
        st.markdown('<div class="search-button-container">', unsafe_allow_html=True)
        search_button = st.button("ğŸ” Ø¨Ø­Ø« ÙˆØ¥Ø¬Ø§Ø¨Ø© Ù…Ø­Ø³Ù†", type="primary", use_container_width=False, key="send_btn")
        st.markdown('</div>', unsafe_allow_html=True)

    # Process search when button is clicked
    if search_button and user_query.strip():
        st.session_state.messages.append({"role": "user", "content": user_query.strip()})
        
        start_time = time.perf_counter()
        bot_msg_data = {"api_used": selected_llm}
        
        # Enhanced search with improved accuracy
        with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø¯Ù‚Ø© ({max_results} Ù†ØªÙŠØ¬Ø©)..."):
            try:
                search_results, search_info, search_details = comprehensive_search(user_query.strip(), max_results)
                bot_msg_data["initial_search_details"] = search_details
                
                # Show real-time debug info
                if show_debug:
                    st.markdown(f'<div class="search-accuracy-boost">ğŸ” <strong>Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©:</strong> ÙˆØ¬Ø¯Øª {len(search_results)} Ù†ØªÙŠØ¬Ø© | {search_info}</div>', unsafe_allow_html=True)
                
            except Exception as search_error:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {search_error}")
                search_results, search_info, search_details = [], f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {str(search_error)}", []

        # Process search results
        if search_results:
            try:
                # Prepare context for LLM
                context_texts = []
                sources_for_llm = []
                total_chars = 0
                max_chars_context = 25000
                
                for i, result in enumerate(search_results):
                    if not result.payload:
                        continue
                    
                    source_id_str = str(result.id) if result.id is not None else f"unknown_id_{i}"
                    source_name = result.payload.get('source', f'ÙˆØ«ÙŠÙ‚Ø© {source_id_str[:6]}')
                    text = result.payload.get('text', '')
                    
                    if text and len(text.strip()) > 10:  # Ensure meaningful text
                        truncated_text = text[:1500] + ("..." if len(text) > 1500 else "")
                        if total_chars + len(truncated_text) < max_chars_context:
                            context_texts.append(f"[Ù†Øµ {i+1} Ù…Ù† '{source_name}']: {truncated_text}")
                            sources_for_llm.append({'source': source_name, 'score': result.score, 'id': result.id})
                            total_chars += len(truncated_text)
                        else:
                            context_texts.append(f"\n[Ù…Ù„Ø§Ø­Ø¸Ø©: ØªÙ… Ø§Ù‚ØªØµØ§Ø± Ø§Ù„Ù†ØµÙˆØµ. {len(search_results)-i} Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù… ÙŠØ±Ø³Ù„.]")
                            search_info += f" | Ø§Ù‚ØªØµØ§Ø± Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ {len(search_results)-i} Ù†ØµÙˆØµ Ù„Ù… ØªØ±Ø³Ù„."
                            break
                
                if context_texts:
                    context_for_llm = "\n\n---\n\n".join(context_texts)
                    llm_context_info = f"Ø£Ø±Ø³Ù„ {len(sources_for_llm)} Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„ (~{total_chars//1000} Ø£Ù„Ù Ø­Ø±Ù)."
                    llm_messages = prepare_llm_messages(user_query.strip(), context_for_llm, llm_context_info)
                    
                    # Get LLM response
                    bot_response = ""
                    with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© {selected_llm}..."):
                        try:
                            if selected_llm == "DeepSeek":
                                bot_response = get_deepseek_response(llm_messages)
                            elif selected_llm == "Gemini":
                                bot_response = get_gemini_response(llm_messages)
                            else:
                                bot_response = "Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø¯Ø¯ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ."
                        except Exception as llm_error:
                            bot_response = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯ Ù…Ù† {selected_llm}: {str(llm_error)}"
                    
                    bot_msg_data["content"] = bot_response
                    bot_msg_data["sources"] = sources_for_llm
                    bot_msg_data["debug_info"] = f"{search_info} | {llm_context_info}" if search_info else llm_context_info
                else:
                    bot_msg_data["content"] = f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(search_results)} Ù†ØªÙŠØ¬Ø© ÙˆÙ„ÙƒÙ† Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ ØµØ§Ù„Ø­Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. ÙŠØ±Ø¬Ù‰ ØªØ¬Ø±Ø¨Ø© ØµÙŠØ§ØºØ© Ù…Ø®ØªÙ„ÙØ© Ù„Ù„Ø³Ø¤Ø§Ù„."
                    bot_msg_data["debug_info"] = f"{search_info} | Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØµÙˆØµ ØµØ§Ù„Ø­Ø© ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"
            
            except Exception as processing_error:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {processing_error}")
                bot_msg_data["content"] = f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(search_results)} Ù†ØªÙŠØ¬Ø© ÙˆÙ„ÙƒÙ† Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(processing_error)}"
                bot_msg_data["debug_info"] = f"{search_info} | Ø®Ø·Ø£ Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(processing_error)}"
        else:
            bot_msg_data["content"] = "Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØªØ¨ ÙˆØ§Ø³ØªÙØªØ§Ø¡Ø§Øª Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯ Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ù…Ø­Ø§ÙˆÙ„Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªÙ„Ù Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø£Ø®Ø±Ù‰."
            bot_msg_data["debug_info"] = search_info if search_info else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù†."
        
        # Save response with timing
        bot_msg_data["role"] = "assistant"
        bot_msg_data["time_taken"] = time.perf_counter() - start_time
        st.session_state.messages.append(bot_msg_data)
        st.rerun()
    
    elif search_button and not user_query.strip():
        st.toast("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„.", icon="ğŸ“")

    # Clear chat button
    with input_main:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True, key="clear_btn", type="secondary"):
            st.session_state.messages = []
            st.toast("ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.", icon="ğŸ—‘ï¸")
            time.sleep(0.5)
            st.rerun()

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.8rem; margin-top: 1rem; font-family: "Noto Sans Arabic", sans-serif;'>
        ğŸš€ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© | ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¨Ø­Ø« Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©<br>
        âœ¨ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø®Ø§ØµØ©: Ø¹ØªØ¨Ø§Øª Ù†Ù‚Ø§Ø· Ù…Ø­Ø³Ù†Ø©ØŒ ÙÙ„ØªØ±Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ù†ØªØ§Ø¦Ø¬ØŒ ØªØ±ØªÙŠØ¨ Ù…ØªÙ‚Ø¯Ù… Ø­Ø³Ø¨ Ø§Ù„ØµÙ„Ø©
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    # Configuration validation
    if not all([QDRANT_API_KEY, QDRANT_URL]):
        st.error("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª QDRANT Ù…ÙÙ‚ÙˆØ¯Ø©. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.")
    if not any([DEEPSEEK_API_KEY, GEMINI_API_KEY]):
        st.info("Ø¨Ø¹Ø¶ Ù…ÙØ§ØªÙŠØ­ LLM API Ù…ÙÙ‚ÙˆØ¯Ø©.", icon="â„¹ï¸")
    
    main()
