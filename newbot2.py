import streamlit as st
import time
from datetime import datetime
import json
import requests
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
import pandas as pd
from openai import OpenAI
import google.generativeai as genai

# ----------------------
# Configuration
# ----------------------
QDRANT_URL = "https://993e7bbb-cbe2-4b82-b672-90c4aed8585e.europe-west3-0.gcp.cloud.qdrant.io:6333"
QDRANT_API_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.qRNtWMTIR32MSM6KUe3lE5qJ0fS5KgyAf86EKQgQ1FQ"
COLLECTION_NAME = "arabic_documents_384"

# API Keys
OPENAI_API_KEY = "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"
DEEPSEEK_API_KEY = "sk-14f267781a6f474a9d0ec8240383dae4"
DEEPSEEK_BASE_URL = "https://api.deepseek.com/v1"
GEMINI_API_KEY = "AIzaSyASlapu6AYYwOQAJJ3v-2FSKHnxIOZoPbY"  # New API key

# Initialize APIs
client = OpenAI(api_key=OPENAI_API_KEY)
genai.configure(api_key=GEMINI_API_KEY)

# ----------------------
# Arabic CSS Styling
# ----------------------
def load_arabic_css():
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Arabic:wght@300;400;500;600;700&display=swap');
    
    .main-header {
        text-align: center;
        color: #2E8B57;
        font-family: 'Noto Sans Arabic', sans-serif;
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        direction: rtl;
    }
    
    .sub-header {
        text-align: center;
        color: #666;
        font-family: 'Noto Sans Arabic', sans-serif;
        font-size: 1.2rem;
        font-weight: 400;
        margin-bottom: 1rem;
        direction: rtl;
    }
    
    .status-box {
        background: #f0f2f6;
        padding: 0.5rem 1rem;
        border-radius: 10px;
        margin: 1rem auto;
        text-align: center;
        font-family: 'Noto Sans Arabic', sans-serif;
        direction: rtl;
        max-width: 400px;
    }
    
    .status-active {
        color: #28a745;
        font-weight: bold;
    }
    
    .status-inactive {
        color: #dc3545;
        font-weight: bold;
    }
    
    .chat-container {
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
    }
    
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px 15px 5px 15px;
        margin: 0.5rem 0;
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
        font-size: 1.1rem;
        font-weight: 500;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    .bot-message {
        background: linear-gradient(135deg, #5DADE2 0%, #3498DB 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px 15px 15px 5px;
        margin: 0.5rem 0;
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
        font-size: 1.1rem;
        font-weight: 500;
        line-height: 1.8;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    .source-container {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 10px;
        margin-top: 1rem;
        direction: rtl;
    }
    
    .source-info {
        background: #f0f2f6;
        padding: 0.5rem;
        border-radius: 10px;
        font-size: 0.85rem;
        color: #666;
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
        border: 1px solid #ddd;
    }
    
    .api-used {
        background: #e3f2fd;
        color: #1976d2;
        padding: 0.3rem 0.6rem;
        border-radius: 5px;
        font-size: 0.85rem;
        margin-top: 0.5rem;
        display: inline-block;
        font-family: 'Noto Sans Arabic', sans-serif;
    }
    
    .stTextArea > div > div > textarea {
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
        font-size: 1.1rem;
        min-height: 100px !important;
    }
    
    .stSelectbox > div > div > select {
        direction: rtl;
        text-align: right;
        font-family: 'Noto Sans Arabic', sans-serif;
    }
    
    .search-button {
        text-align: center;
        margin-top: 1rem;
    }
    
    div[data-testid="stButton"] > button {
        width: 200px;
        margin: 0 auto;
        display: block;
    }
    </style>
    """, unsafe_allow_html=True)

# ----------------------
# Database Status Check
# ----------------------
@st.cache_data(ttl=60)  # Cache for 1 minute
def check_database_status():
    """Check if Qdrant database is connected and active"""
    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        collection_info = client.get_collection(COLLECTION_NAME)
        point_count = collection_info.points_count
        return True, point_count
    except Exception as e:
        print(f"Database connection error: {e}")
        return False, 0

# ----------------------
# Initialize Components
# ----------------------
@st.cache_resource
def init_qdrant_client():
    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        return client
    except Exception as e:
        st.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return None

@st.cache_resource
def init_embedding_model():
    try:
        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        return model
    except Exception as e:
        st.error(f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ†: {e}")
        return None

# ----------------------
# API Response Functions
# ----------------------
def get_openai_response(messages):
    """Get response from OpenAI API"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.3,  # Lower temperature for more focused responses
            max_tokens=1500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ OpenAI API: {e}")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† OpenAI."

def get_deepseek_response(messages):
    """Get response from DeepSeek API"""
    try:
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "deepseek-chat",
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 1500,
            "stream": False
        }
        
        response = requests.post(
            f"{DEEPSEEK_BASE_URL}/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ DeepSeek API: {response.status_code}")
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† DeepSeek."
            
    except Exception as e:
        st.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {e}")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ."

def get_gemini_response(messages):
    """Get response from Gemini API"""
    try:
        # Try different model names
        model_names = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
        
        for model_name in model_names:
            try:
                model = genai.GenerativeModel(model_name)
                
                # Format messages for Gemini
                prompt = ""
                for msg in messages:
                    if msg["role"] == "system":
                        prompt += f"Ø§Ù„Ù†Ø¸Ø§Ù…: {msg['content']}\n\n"
                    elif msg["role"] == "user":
                        prompt += f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {msg['content']}\n\n"
                
                response = model.generate_content(prompt)
                return response.text
            except:
                continue
                
        # If all models fail
        st.error("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ù…ÙŠØ¹ Ù†Ù…Ø§Ø°Ø¬ Gemini Ø§Ù„Ù…ØªØ§Ø­Ø©")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Gemini."
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Gemini API: {e}")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Gemini."

# ----------------------
# Document Search Function
# ----------------------
def search_documents(query, top_k=10):  # Increased to search more documents
    """Search for relevant documents using vector similarity"""
    try:
        embedding_model = init_embedding_model()
        if not embedding_model:
            return []
        
        query_embedding = embedding_model.encode([query])[0].tolist()
        
        qdrant_client = init_qdrant_client()
        if not qdrant_client:
            return []
        
        # Search with higher limit to get more comprehensive results
        search_results = qdrant_client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_embedding,
            limit=top_k,
            with_payload=True,
            score_threshold=0.3  # Lower threshold to include more results
        )
        
        return search_results
        
    except Exception as e:
        st.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
        return []

# ----------------------
# Main Application
# ----------------------
def main():
    st.set_page_config(
        page_title="Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¯ÙŠÙ†ÙŠ Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯ - Ø¯Ø§Ù… Ø¸Ù„Ù‡",
        page_icon="ğŸ•Œ",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # Load Arabic CSS
    load_arabic_css()
    
    # Header
    st.markdown('<h1 class="main-header">Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¯ÙŠÙ†ÙŠ Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯ - Ø¯Ø§Ù… Ø¸Ù„Ù‡</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Ù…Ø­Ø±Ùƒ Ø¨Ø­Ø« Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ø§Ø³ØªÙØªØ§Ø¡Ø§Øª</p>', unsafe_allow_html=True)
    
    # Database Status
    db_status, vector_count = check_database_status()
    if db_status:
        st.markdown(f'<div class="status-box">Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: <span class="status-active">Ù…ØªØµÙ„ âœ“</span> | Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª: {vector_count:,}</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="status-box">Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: <span class="status-inactive">ØºÙŠØ± Ù…ØªØµÙ„ âœ—</span></div>', unsafe_allow_html=True)
    
    # Search Engine Selection
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        search_engine = st.selectbox(
            "Ø§Ø®ØªØ± Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ",
            ["OpenAI API", "DeepSeek", "Gemini"],
            index=0,
            key="search_engine"
        )
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Display chat history
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.markdown(f'<div class="user-message">ğŸ‘¤ {message["content"]}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="bot-message">ğŸ¤– {message["content"]}</div>', unsafe_allow_html=True)
                
                # Display API used
                if "api_used" in message:
                    st.markdown(f'<span class="api-used">ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…: {message["api_used"]}</span>', unsafe_allow_html=True)
                
                # Display sources in grid
                if "sources" in message and message["sources"]:
                    st.markdown('<div class="source-container">', unsafe_allow_html=True)
                    cols = st.columns(3)
                    for idx, source in enumerate(message["sources"][:6]):  # Show up to 6 sources
                        with cols[idx % 3]:
                            percentage = source["score"] * 100
                            st.markdown(
                                f'<div class="source-info">ğŸ“„ Ø§Ù„Ù…ØµØ¯Ø±: {source["source"]}<br>Ø§Ù„ØªØ·Ø§Ø¨Ù‚: {percentage:.1f}%</div>', 
                                unsafe_allow_html=True
                            )
                    st.markdown('</div>', unsafe_allow_html=True)
    
    # Chat input with larger text area
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Create centered columns for input
    col1, col2, col3 = st.columns([1, 3, 1])
    
    with col2:
        user_question = st.text_area(
            "Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...",
            placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§... Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡Ùˆ Ø­ÙƒÙ… Ø§Ù„ØµÙ„Ø§Ø© ÙÙŠ Ø§Ù„Ø³ÙØ±ØŸ",
            key="user_input",
            height=100
        )
        
        # Centered search button
        st.markdown('<div class="search-button">', unsafe_allow_html=True)
        send_button = st.button("ğŸ” Ø¨Ø­Ø«", type="primary", use_container_width=False)
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Process user input
    if send_button and user_question:
        # Add user message to history
        st.session_state.messages.append({"role": "user", "content": user_question})
        
        # Search for relevant documents
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒØªØ¨ ÙˆØ§Ù„Ø§Ø³ØªÙØªØ§Ø¡Ø§Øª..."):
            search_results = search_documents(user_question, top_k=10)
        
        if search_results:
            # Prepare context for AI
            context_texts = []
            sources = []
            
            # Use more results for context
            for result in search_results:
                context_texts.append(result.payload.get('text', ''))
                sources.append({
                    'source': result.payload.get('source', 'Ù…Ø¬Ù‡ÙˆÙ„'),
                    'score': result.score
                })
            
            context = "\n\n".join(context_texts)
            
            # Prepare messages for AI with stricter system prompt
            system_prompt = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© ÙˆØ§Ù„Ø´Ø±Ø¹ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒØªØ¨ ÙˆØ§Ø³ØªÙØªØ§Ø¡Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¯ÙŠÙ†ÙŠ Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯ ÙÙ‚Ø·.
            
            Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹:
            1. Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© - Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬ Ù‡Ø°Ù‡ Ø§Ù„Ù†ØµÙˆØµ
            2. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©ØŒ Ù‚Ù„ "Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§ÙÙŠØ© ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©"
            3. Ù„Ø§ ØªØ³ØªÙ†ØªØ¬ Ø£Ùˆ ØªØ®Ù…Ù† Ø£Ùˆ ØªØ¶ÙŠÙ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ
            4. Ø§Ù‚ØªØ¨Ø³ Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†
            5. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙÙ‚Ø·
            6. ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ ÙÙŠ Ù†Ù‚Ù„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø´Ø±Ø¹ÙŠØ© ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø±
            7. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¬Ø²Ø¦ÙŠØ§Ù‹ØŒ Ø§Ø°ÙƒØ± Ù…Ø§ ÙˆØ¬Ø¯ØªÙ‡ ÙˆØ§Ø°ÙƒØ± Ø£Ù† Ù‡Ù†Ø§Ùƒ ØªÙØ§ØµÙŠÙ„ Ø£Ø®Ø±Ù‰ Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ø·Ù„ÙˆØ¨Ø©
            """
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† ÙƒØªØ¨ ÙˆØ§Ø³ØªÙØªØ§Ø¡Ø§Øª Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯:\n{context}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {user_question}\n\nØ£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡."}
            ]
            
            # Get response based on selected engine
            with st.spinner(f"Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {search_engine}..."):
                if search_engine == "OpenAI API":
                    bot_response = get_openai_response(messages)
                elif search_engine == "DeepSeek":
                    bot_response = get_deepseek_response(messages)
                else:  # Gemini
                    bot_response = get_gemini_response(messages)
            
            # Add bot response to history
            st.session_state.messages.append({
                "role": "assistant", 
                "content": bot_response,
                "sources": sources[:6],  # Show top 6 sources
                "api_used": search_engine
            })
        else:
            # No relevant documents found
            st.session_state.messages.append({
                "role": "assistant", 
                "content": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© ÙÙŠ ÙƒØªØ¨ ÙˆØ§Ø³ØªÙØªØ§Ø¡Ø§Øª Ø§Ù„Ø´ÙŠØ® Ù…Ø­Ù…Ø¯ Ø§Ù„Ø³Ù†Ø¯ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù…ÙˆØ¶ÙˆØ¹ Ø¢Ø®Ø±.",
                "api_used": search_engine
            })
        
        # Rerun to update chat
        st.rerun()
    
    # Clear chat button
    col1, col2, col3 = st.columns([1, 3, 1])
    with col2:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

# ----------------------
# Run the Application
# ----------------------
if __name__ == "__main__":
    main()
